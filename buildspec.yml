version: 0.2

env:
  # Reference the secret stored in AWS Secrets Manager
  # These provide the DOCKERHUB_USERNAME and DOCKERHUB_PASSWORD variables
  secrets-manager:
    DOCKERHUB_USERNAME: DockerHubCredentialsForGenDJ:DOCKERHUB_USERNAME # SecretName:JSONKey
    DOCKERHUB_PASSWORD: DockerHubCredentialsForGenDJ:DOCKERHUB_PASSWORD # SecretName:JSONKey
  # IMAGE_REPO_NAME and IMAGE_TAG are expected to be set as environment
  # variables directly on the CodeBuild project by the setup_codebuild.py script.

phases: # Top level key
  install: # Level 1 dictionary key under phases
    runtime-versions:
      python: 3.10 # Explicitly request Python 3.10
    commands: # Level 2 list key under install
      - echo "--- Install Phase ---"
      - echo "Checking system info..."
      - nvidia-smi || echo "nvidia-smi not found or failed (Might be okay)"
      - python --version # Should now show 3.10 after runtime install
      - pip --version || pip3 --version || echo "Pip not found"
      - echo "Installing Python dependencies from requirements.txt..."
      # Now pip should be using the requested Python 3.10
      - pip install --cache-dir .pip-cache -r requirements.txt || pip3 install --cache-dir .pip-cache -r requirements.txt

  pre_build: # Level 1 dictionary key under phases
    commands: # Level 2 list key under pre_build
      - echo "--- Pre-Build Phase ---"
      - echo "Running model caching script (cache-models.py)..."
      # Use the installed Python 3.10
      - python cache-models.py || (echo "Model caching script failed!" && exit 1)
      # --- Add ls command for debugging ---
      - echo "Listing contents of saved_pipeline/taesdxl/ after caching:"
      - ls -l saved_pipeline/taesdxl/
      # --- Add Rename Step --- 
      - echo "Renaming VAE model file to expected .bin format..."
      - | 
        if [ -f "saved_pipeline/taesdxl/diffusion_pytorch_model.fp16.safetensors" ]; then 
          mv "saved_pipeline/taesdxl/diffusion_pytorch_model.fp16.safetensors" "saved_pipeline/taesdxl/diffusion_pytorch_model.bin" && \
          echo "Successfully renamed VAE model file."; 
        else 
          echo "WARNING: Expected VAE file diffusion_pytorch_model.fp16.safetensors not found for renaming.";
          # Decide if this should be a fatal error
          # exit 1 
        fi
      # --- End Rename Step ---
      # --- Add ls command for sdxl-turbo debugging ---
      - echo "Listing contents of saved_pipeline/sdxl-turbo/ after caching:"
      - ls -l saved_pipeline/sdxl-turbo/
      # --- End ls command ---
      - echo "Verifying cached model files (individual checks)..."
      # --- Individual File Checks (Adjusted for sdxl-turbo structure) ---
      - test -f "saved_pipeline/taesdxl/config.json" || (echo "Missing taesdxl/config.json" && exit 1)
      # Check for .bin file now (after potential rename)
      - test -f "saved_pipeline/taesdxl/diffusion_pytorch_model.bin" || (echo "Missing taesdxl/diffusion_pytorch_model.bin AFTER rename attempt" && exit 1)
      # - test -f "saved_pipeline/sdxl-turbo/model_index.json" || (echo "Missing sdxl-turbo/model_index.json" && exit 1) # REMOVED - Assuming saved in subdirs
      # - test -f "saved_pipeline/sdxl-turbo/config.json" || (echo "Missing sdxl-turbo/config.json" && exit 1) # REMOVED - Assuming saved in subdirs
      # Rely on subdirectory checks:
      - test -f "saved_pipeline/sdxl-turbo/vae/config.json" || (echo "Missing sdxl-turbo/vae/config.json" && exit 1)
      - test -f "saved_pipeline/sdxl-turbo/unet/config.json" || (echo "Missing sdxl-turbo/unet/config.json" && exit 1)
      - test -f "saved_pipeline/sdxl-turbo/text_encoder/config.json" || (echo "Missing sdxl-turbo/text_encoder/config.json" && exit 1)
      - test -f "saved_pipeline/sdxl-turbo/text_encoder_2/config.json" || (echo "Missing sdxl-turbo/text_encoder_2/config.json" && exit 1)
      - test -f "saved_pipeline/sdxl-turbo/scheduler/scheduler_config.json" || (echo "Missing sdxl-turbo/scheduler/scheduler_config.json" && exit 1)
      - test -f "saved_pipeline/sdxl-turbo/tokenizer/tokenizer_config.json" || (echo "Missing sdxl-turbo/tokenizer/tokenizer_config.json" && exit 1)
      - test -f "saved_pipeline/sdxl-turbo/tokenizer_2/tokenizer_config.json" || (echo "Missing sdxl-turbo/tokenizer_2/tokenizer_config.json" && exit 1)
      # Add checks for actual weight files if needed, e.g.:
      # - test -f "saved_pipeline/sdxl-turbo/unet/diffusion_pytorch_model.fp16.safetensors" || (echo "Missing sdxl-turbo/unet/...safetensors" && exit 1)
      - echo "Required cached sub-directory files verified successfully." # Adjusted message
      # --- End Individual File Checks ---
      - echo "Logging in to Docker Hub..."
      # Ensure DOCKERHUB_USERNAME and DOCKERHUB_PASSWORD vars are correctly populated by env.secrets-manager
      - echo $DOCKERHUB_PASSWORD | docker login -u $DOCKERHUB_USERNAME --password-stdin || (echo "Docker login failed!" && exit 1)

  build: # Level 1 dictionary key under phases
    commands: # Level 2 list key under build
      - echo "--- Build Phase ---"
      # IMAGE_REPO_NAME and IMAGE_TAG come from CodeBuild project environment variables
      - echo "Building Docker image $IMAGE_REPO_NAME:$IMAGE_TAG"
      - docker build -t $IMAGE_REPO_NAME:$IMAGE_TAG -f Dockerfile.serverless . || (echo "Docker build failed!" && exit 1)

  post_build: # Level 1 dictionary key under phases
    commands: # Level 2 list key under post_build
      - echo "--- Post-Build Phase ---"
      # IMAGE_REPO_NAME and IMAGE_TAG come from CodeBuild project environment variables
      - echo "Pushing Docker image to Docker Hub $IMAGE_REPO_NAME:$IMAGE_TAG"
      - docker push $IMAGE_REPO_NAME:$IMAGE_TAG || (echo "Docker push failed!" && exit 1)
      - echo "Build and push completed successfully."

# artifacts: # Top level key (Ensure this line starts at column 0 or same level as 'phases' and 'env')
#   files:   # Level 1 dictionary key under artifacts
#     - '**/*' # Level 2 list item
